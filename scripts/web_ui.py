#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ¬åœ°çŸ¥è¯†åº“ Web UI
ä½¿ç”¨ Gradio æ„å»ºäº¤äº’ç•Œé¢
"""

import gradio as gr
import os
from knowledge_base import LocalKnowledgeBase
from datetime import datetime


class KnowledgeBaseUI:
    """çŸ¥è¯†åº“ Web UI ç±»"""
    
    def __init__(self):
        self.kb = LocalKnowledgeBase('config.yaml')
        self.chat_history = []
    
    def build_kb_stream(self, docs_dir: str, rebuild: bool):
        """æµå¼æ„å»ºçŸ¥è¯†åº“çš„ UI å›è°ƒ"""
        import os
        if not docs_dir or not os.path.exists(docs_dir):
            yield "âŒ é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„æ–‡æ¡£ç›®å½•è·¯å¾„"
            return
        
        try:
            # å¼€å§‹æ„å»º
            yield "ğŸš€ å¼€å§‹æ„å»ºçŸ¥è¯†åº“...\n"
            
            # æ‰«ææ–‡æ¡£
            yield "ğŸ“ æ­£åœ¨æ‰«ææ–‡æ¡£ç›®å½•...\n"
            import glob
            files = []
            for ext in ['*.txt', '*.md', '*.pdf', '*.docx', '*.epub']:
                files.extend(glob.glob(os.path.join(docs_dir, ext)))
            yield f"ğŸ“„ æ‰¾åˆ° {len(files)} ä¸ªæ–‡æ¡£æ–‡ä»¶\n"
            
            # åŠ è½½åµŒå…¥æ¨¡å‹
            yield "ğŸ§  æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹...\n"
            self.kb._initialize_embeddings()
            yield "âœ… åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆ\n"
            
            # åŠ è½½æ–‡æ¡£
            yield "ğŸ“– æ­£åœ¨åŠ è½½æ–‡æ¡£...\n"
            documents = []
            for i, file_path in enumerate(files):
                try:
                    doc = self.kb._load_document(file_path)
                    documents.extend(doc)
                    yield f"  âœ“ {os.path.basename(file_path)}\n"
                except Exception as e:
                    yield f"  âŒ {os.path.basename(file_path)}: {str(e)}\n"
            
            # åˆ†å‰²æ–‡æ¡£
            yield f"âœ‚ï¸ æ­£åœ¨åˆ†å‰²æ–‡æ¡£...\n"
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.kb.config['document_processing']['chunk_size'],
                chunk_overlap=self.kb.config['document_processing']['chunk_overlap'],
                separators=self.kb.config['document_processing']['separators']
            )
            splits = text_splitter.split_documents(documents)
            yield f"âœ… æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…± {len(splits)} ä¸ªæ–‡æ¡£å—\n"
            
            # åˆ›å»ºå‘é‡æ•°æ®åº“
            yield "ğŸ” æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“...\n"
            from langchain.vectorstores import Chroma
            import os
            os.environ["ANONYMIZED_TELEMETRY"] = "False"
            persist_dir = self.kb.config['chroma']['persist_directory']
            if rebuild and os.path.exists(persist_dir):
                import shutil
                shutil.rmtree(persist_dir)
                yield "ğŸ—‘ï¸ å·²åˆ é™¤ç°æœ‰æ•°æ®\n"
            
            self.kb.vectorstore = Chroma.from_documents(
                documents=splits,
                embedding=self.kb.embeddings,
                persist_directory=persist_dir,
                collection_name=self.kb.config['chroma']['collection_name']
            )
            yield "âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ\n"
            
            # å®Œæˆ
            yield f"\nğŸ‰ çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼\n"
            yield f"ğŸ“ ç›®å½•: {docs_dir}\n"
            yield f"ğŸ“„ æ–‡æ¡£: {len(files)} ä¸ªæ–‡ä»¶\n"
            yield f"ğŸ“ å—æ•°: {len(splits)} ä¸ªæ–‡æ¡£å—\n"
            yield f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            
        except Exception as e:
            yield f"âŒ æ„å»ºå¤±è´¥: {str(e)}"
    
    def query_kb(self, question: str, history: list) -> tuple:
        """æŸ¥è¯¢çŸ¥è¯†åº“çš„ UI å›è°ƒ"""
        if not question.strip():
            return history, history
        
        try:
            # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°å†å²
            history.append((question, ""))
            
            # è·å–ç­”æ¡ˆ
            answer, sources = self.kb.query(question, show_sources=False)
            
            # ç›´æ¥ä½¿ç”¨ç­”æ¡ˆï¼Œä¸æ˜¾ç¤ºå‚è€ƒæ¥æº
            full_answer = answer
            
            # æ›´æ–°å†å²ä¸­çš„ç­”æ¡ˆ
            history[-1] = (question, full_answer)
            
            return history, history
            
        except Exception as e:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
            history.append((question, error_msg))
            return history, history
    
    def query_kb_stream(self, question: str, history: list):
        """æµå¼æŸ¥è¯¢çŸ¥è¯†åº“çš„ UI å›è°ƒ"""
        if not question.strip():
            yield history, history
            return
        
        try:
            from datetime import datetime
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°å†å²ï¼Œåˆå§‹æ˜¾ç¤ºç­‰å¾…çŠ¶æ€
            history.append((question, "ğŸ¤” æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“..."))
            yield history, history
            
            # æµå¼è·å–ç­”æ¡ˆ
            answer_parts = []
            sources = []
            chunk_count = 0
            
            for chunk, docs in self.kb.query_stream(question, show_sources=False):
                chunk_count += 1
                answer_parts.append(chunk)
                
                # è®¡ç®—å·²ç»è¿‡çš„æ—¶é—´
                elapsed_time = (datetime.now() - start_time).total_seconds()
                
                # æ˜¾ç¤ºç­”æ¡ˆå†…å®¹å’Œå®æ—¶æ—¶é—´
                current_answer = "".join(answer_parts)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆçš„æ—¶é—´ä¿¡æ¯ï¼ˆåŒ…å«"ç”Ÿæˆæ—¶é—´"ï¼‰
                if "**ç”Ÿæˆæ—¶é—´**" in current_answer:
                    # è¿™æ˜¯æœ€ç»ˆç»“æœï¼Œä¿æŒåŸæ ·
                    history[-1] = (question, current_answer)
                else:
                    # ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæ˜¾ç¤ºå®æ—¶è¿›åº¦
                    display_answer = current_answer + f"\n\nâ±ï¸ *ç”Ÿæˆä¸­... {elapsed_time:.1f}ç§’*"
                    history[-1] = (question, display_answer)
                
                yield history, history
                
        except Exception as e:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
            history.append((question, error_msg))
            yield history, history
    
    def query_kb_with_file_stream(self, question: str, file_path: str, history: list):
        """å¸¦æ–‡ä»¶ä¸Šä¼ çš„æµå¼æŸ¥è¯¢"""
        from datetime import datetime
        
        # å¦‚æœæ²¡æœ‰é—®é¢˜ä¹Ÿæ²¡æœ‰æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
        if not question.strip() and not file_path:
            yield history, history
            return
        
        try:
            start_time = datetime.now()
            
            # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
            if file_path:
                # æ·»åŠ æ–‡ä»¶å¤„ç†æç¤º
                history.append((f"ğŸ“ å·²ä¸Šä¼ æ–‡ä»¶: {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", "ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶..."))
                yield history, history
                
                # åŠ è½½æ–‡ä»¶å†…å®¹
                try:
                    history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", "ğŸ“– æ­£åœ¨è§£ææ–‡ä»¶å†…å®¹...")
                    yield history, history
                    
                    doc = self.kb._load_document(file_path)
                    if doc:
                        # æå–æ–‡ä»¶å†…å®¹
                        file_content = "\n\n".join([d.page_content for d in doc])
                        
                        history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", "ğŸ§  æ­£åœ¨åˆ†ææ–‡ä»¶å†…å®¹...")
                        yield history, history
                        
                        # æ„å»ºå¸¦æ–‡ä»¶å†…å®¹çš„é—®é¢˜
                        if question.strip():
                            enhanced_question = f"åŸºäºä»¥ä¸‹æ–‡ä»¶å†…å®¹å›ç­”é—®é¢˜ï¼š\n\næ–‡ä»¶å†…å®¹ï¼š\n{file_content[:3000]}\n\né—®é¢˜ï¼š{question}"
                        else:
                            enhanced_question = f"è¯·åˆ†æå¹¶æ€»ç»“ä»¥ä¸‹æ–‡ä»¶çš„ä¸»è¦å†…å®¹ï¼š\n\n{file_content[:3000]}"
                        
                        history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", "ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
                        yield history, history
                    else:
                        error_msg = "âŒ æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œæ ¼å¼å¯èƒ½ä¸æ”¯æŒ"
                        history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", error_msg)
                        yield history, history
                        return
                except Exception as e:
                    error_msg = f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
                    history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", error_msg)
                    yield history, history
                    return
            else:
                # æ²¡æœ‰æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨é—®é¢˜
                enhanced_question = question
                history.append((question, "ğŸ¤” æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“..."))
                yield history, history
            
            # æµå¼è·å–ç­”æ¡ˆ
            answer_parts = []
            
            # ä½¿ç”¨ LLM ç›´æ¥å›ç­”ï¼ˆå¸¦æ–‡ä»¶å†…å®¹ï¼‰
            if file_path:
                from langchain.prompts import PromptTemplate
                
                prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚åˆ†æå†…å®¹å¹¶å›ç­”ã€‚

{question}

è¯·ç”¨ä¸­æ–‡è¯¦ç»†å›ç­”ï¼Œä½¿ç”¨æ¸…æ™°çš„ Markdown æ ¼å¼ã€‚"""
                
                prompt = prompt_template.format(question=enhanced_question)
                
                # åˆå§‹åŒ– LLMï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                self.kb._initialize_llm()
                
                # æµå¼è¾“å‡º
                response = self.kb.llm.stream(prompt)
                
                for chunk in response:
                    if hasattr(chunk, 'content') and chunk.content:
                        content = str(chunk.content)
                        if content:
                            answer_parts.append(content)
                    elif isinstance(chunk, str):
                        content = str(chunk)
                        if content:
                            answer_parts.append(content)
                    
                    # è®¡ç®—å·²ç»è¿‡çš„æ—¶é—´
                    elapsed_time = (datetime.now() - start_time).total_seconds()
                    
                    # æ˜¾ç¤ºç­”æ¡ˆå†…å®¹å’Œå®æ—¶æ—¶é—´
                    current_answer = "".join(answer_parts)
                    display_answer = current_answer + f"\n\nâ±ï¸ *ç”Ÿæˆä¸­... {elapsed_time:.1f}ç§’*"
                    history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", display_answer)
                    
                    yield history, history
            else:
                # æ²¡æœ‰æ–‡ä»¶ï¼Œä½¿ç”¨çŸ¥è¯†åº“æŸ¥è¯¢
                for chunk, docs in self.kb.query_stream(question, show_sources=False):
                    answer_parts.append(chunk)
                    
                    # è®¡ç®—å·²ç»è¿‡çš„æ—¶é—´
                    elapsed_time = (datetime.now() - start_time).total_seconds()
                    
                    # æ˜¾ç¤ºç­”æ¡ˆå†…å®¹å’Œå®æ—¶æ—¶é—´
                    current_answer = "".join(answer_parts)
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆçš„æ—¶é—´ä¿¡æ¯ï¼ˆåŒ…å«"ç”Ÿæˆæ—¶é—´"ï¼‰
                    if "**ç”Ÿæˆæ—¶é—´**" in current_answer:
                        history[-1] = (question, current_answer)
                    else:
                        display_answer = current_answer + f"\n\nâ±ï¸ *ç”Ÿæˆä¸­... {elapsed_time:.1f}ç§’*"
                        history[-1] = (question, display_answer)
                    
                    yield history, history
            
            # è®¡ç®—æ€»æ—¶é—´
            end_time = datetime.now()
            generation_time = (end_time - start_time).total_seconds()
            
            # å¦‚æœæ˜¯æ–‡ä»¶æŸ¥è¯¢ï¼Œæ·»åŠ æ—¶é—´ä¿¡æ¯
            if file_path and "**ç”Ÿæˆæ—¶é—´**" not in "".join(answer_parts):
                final_answer = "".join(answer_parts) + f"\n\nâ±ï¸ **ç”Ÿæˆæ—¶é—´**: {generation_time:.2f}ç§’"
                history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", final_answer)
                yield history, history
                
        except Exception as e:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
            if file_path:
                history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question}", error_msg)
            else:
                history.append((question, error_msg))
            yield history, history
    
    def query_and_clear(self, question: str, file_path: str, history: list):
        """æŸ¥è¯¢å¹¶æ¸…é™¤è¾“å…¥ï¼ˆç”¨äºäº‹ä»¶é“¾ï¼‰"""
        # è¿™ä¸ªå‡½æ•°ä¼šè¢«ç«‹å³è°ƒç”¨ï¼Œè¿”å›æ¸…ç©ºçš„å€¼å’Œä¿å­˜çš„è¾“å…¥
        return question, file_path, history, "", None
    
    def handle_submit(self, question: str, file_path: str, history: list):
        """å¤„ç†æäº¤ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰"""
        if not question.strip() and not file_path:
            return history, history
        
        try:
            from datetime import datetime
            start_time = datetime.now()
            
            # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
            if file_path:
                # æ·»åŠ æ–‡ä»¶å¤„ç†æç¤º
                history.append((f"ğŸ“ å·²ä¸Šä¼ æ–‡ä»¶: {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", "ğŸ“‚ æ­£åœ¨å¤„ç†æ–‡ä»¶..."))
                
                # åŠ è½½æ–‡ä»¶å†…å®¹
                try:
                    doc = self.kb._load_document(file_path)
                    if doc:
                        # æå–æ–‡ä»¶å†…å®¹
                        file_content = "\n\n".join([d.page_content for d in doc])
                        
                        # æ„å»ºå¸¦æ–‡ä»¶å†…å®¹çš„é—®é¢˜
                        if question.strip():
                            enhanced_question = f"åŸºäºä»¥ä¸‹æ–‡ä»¶å†…å®¹å›ç­”é—®é¢˜ï¼š\n\næ–‡ä»¶å†…å®¹ï¼š\n{file_content[:3000]}\n\né—®é¢˜ï¼š{question}"
                        else:
                            enhanced_question = f"è¯·åˆ†æå¹¶æ€»ç»“ä»¥ä¸‹æ–‡ä»¶çš„ä¸»è¦å†…å®¹ï¼š\n\n{file_content[:3000]}"
                        
                        # ä½¿ç”¨ LLM ç›´æ¥å›ç­”
                        self.kb._initialize_llm()
                        response = self.kb.llm.invoke(enhanced_question)
                        
                        # è®¡ç®—æ—¶é—´
                        end_time = datetime.now()
                        generation_time = (end_time - start_time).total_seconds()
                        
                        # æ·»åŠ æ—¶é—´ä¿¡æ¯
                        final_answer = str(response) + f"\n\nâ±ï¸ **ç”Ÿæˆæ—¶é—´**: {generation_time:.2f}ç§’"
                        history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", final_answer)
                    else:
                        error_msg = "âŒ æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œæ ¼å¼å¯èƒ½ä¸æ”¯æŒ"
                        history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", error_msg)
                except Exception as e:
                    error_msg = f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
                    history[-1] = (f"ğŸ“ {file_path.split('/')[-1]}\n{question if question.strip() else 'è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶'}", error_msg)
            else:
                # æ²¡æœ‰æ–‡ä»¶ï¼Œä½¿ç”¨çŸ¥è¯†åº“æŸ¥è¯¢
                answer, sources = self.kb.query(question, show_sources=False)
                history[-1] = (question, answer)
            
            return history, history
            
        except Exception as e:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
            history.append((question, error_msg))
            return history, history
    
    def clear_inputs(self):
        """æ¸…é™¤è¾“å…¥æ¡†å’Œæ–‡ä»¶"""
        print("ğŸ”„ æ¸…é™¤è¾“å…¥æ¡†å’Œæ–‡ä»¶...")  # è°ƒè¯•ä¿¡æ¯
        return "", None
    
    def clear_chat(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.kb.memory.clear()
        self.chat_history = []
        return [], []
    
    def launch(self):
        """å¯åŠ¨ Web UI"""
        
        # è‡ªå®šä¹‰ CSS
        custom_css = """
        .gradio-container {
            font-family: 'Arial', sans-serif;
        }
        .chatbot {
            height: 500px;
        }
        .compact-file-upload {
            height: 120px !important;
            min-height: 120px !important;
        }
        .compact-file-upload .upload-button {
            height: 120px !important;
            min-height: 120px !important;
            padding: 8px !important;
        }
        .compact-file-upload .upload-text {
            font-size: 12px !important;
        }
        """
        
        with gr.Blocks(title="æœ¬åœ°çŸ¥è¯†åº“ç³»ç»Ÿ", css=custom_css, theme=gr.themes.Soft()) as demo:
            
            gr.Markdown("""
            # ğŸ§  æœ¬åœ°çŸ¥è¯†åº“ç³»ç»Ÿ
            
            åŸºäº **Ollama + ChromaDB + Sentence Transformers** æ„å»ºçš„å®Œå…¨æœ¬åœ°åŒ–çŸ¥è¯†åº“
            
            ### âœ¨ ç‰¹ç‚¹
            - ğŸ”’ **å®Œå…¨ç§æœ‰**: æ‰€æœ‰æ•°æ®åœ¨æœ¬åœ°å¤„ç†ï¼Œä¸ä¸Šä¼ äº‘ç«¯
            - ğŸ’° **å®Œå…¨å…è´¹**: æ— éœ€ä»»ä½• API è´¹ç”¨
            - ğŸš€ **å³æ—¶å“åº”**: æœ¬åœ°è¿è¡Œï¼Œå“åº”å¿«é€Ÿ
            - ğŸŒ **ä¸­æ–‡ä¼˜åŒ–**: æ”¯æŒä¸­æ–‡æ–‡æ¡£å’Œå¯¹è¯
            """)
            
            with gr.Tab("ğŸ’¬ å¯¹è¯æŸ¥è¯¢"):
                with gr.Row():
                    with gr.Column(scale=1):
                        chatbot = gr.Chatbot(
                            label="å¯¹è¯å†å²",
                            height=500,
                            bubble_full_width=False,
                            render_markdown=True,
                            show_label=True,
                            container=True
                        )
                        
                        with gr.Row():
                            with gr.Column(scale=15):
                                question_input = gr.Textbox(
                                    label="è¾“å…¥ä½ çš„é—®é¢˜",
                                    placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼Ÿ",
                                    lines=1,
                                    max_lines=1
                                )
                            with gr.Column(scale=1):
                                file_upload = gr.File(
                                    label="ğŸ“æ–‡ä»¶ä¸Šä¼ ",
                                    file_types=[".txt", ".md", ".pdf", ".docx", ".epub"],
                                    type="filepath",
                                    container=False,
                                    show_label=True,
                                    elem_classes=["compact-file-upload"]
                            )
                        
                        with gr.Row():
                            clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å†å²")
                            submit_btn = gr.Button("ğŸš€ æé—®", variant="primary")

                
                # èŠå¤©çŠ¶æ€
                chat_state = gr.State([])
                
                # ç‚¹å‡»æŒ‰é’®å‘é€ - ä½¿ç”¨æµå¼è¾“å‡º
                def clear_all():
                    """æ¸…é™¤æ‰€æœ‰è¾“å…¥"""
                    return gr.update(value=""), gr.update(value=None)
                
                submit_event = submit_btn.click(
                    fn=self.query_kb_with_file_stream,
                    inputs=[question_input, file_upload, chat_state],
                    outputs=[chatbot, chat_state]
                )
                submit_event.then(
                    fn=clear_all,  # å‘é€åæ¸…é™¤
                    inputs=None,
                    outputs=[question_input, file_upload]
                )
                
                # æŒ‰å›è½¦é”®å‘é€ - ä½¿ç”¨æµå¼è¾“å‡º
                submit_event2 = question_input.submit(
                    fn=self.query_kb_with_file_stream,
                    inputs=[question_input, file_upload, chat_state],
                    outputs=[chatbot, chat_state]
                )
                submit_event2.then(
                    fn=clear_all,  # å‘é€åæ¸…é™¤
                    inputs=None,
                    outputs=[question_input, file_upload]
                )
                
                clear_btn.click(
                    fn=self.clear_chat,
                    outputs=[chatbot, chat_state]
                )
            
            with gr.Tab("ğŸ”¨ æ„å»ºçŸ¥è¯†åº“"):
                gr.Markdown("""
                ## æ„å»ºæˆ–æ›´æ–°çŸ¥è¯†åº“
                
                å°†ä½ çš„æ–‡æ¡£æ”¾å…¥æŒ‡å®šç›®å½•ï¼Œç„¶åç‚¹å‡»æ„å»ºæŒ‰é’®ã€‚
                
                **æ”¯æŒçš„æ–‡æ¡£æ ¼å¼**: TXT, PDF, DOCX, Markdown, EPUB
                """)
                
                with gr.Row():
                    docs_dir_input = gr.Textbox(
                        label="æ–‡æ¡£ç›®å½•è·¯å¾„",
                        placeholder="ä¾‹å¦‚: docs æˆ– /Users/username/Documents/my_docs",
                        value="../docs"
                    )
                
                with gr.Row():
                    rebuild_checkbox = gr.Checkbox(
                        label="é‡æ–°æ„å»ºï¼ˆåˆ é™¤ç°æœ‰æ•°æ®ï¼‰",
                        value=False
                    )
                
                build_btn = gr.Button("ğŸ”¨ å¼€å§‹æ„å»º", variant="primary", size="lg")
                build_output = gr.Textbox(
                    label="æ„å»ºè¿›åº¦",
                    lines=2,
                    interactive=False,
                    show_copy_button=True
                )
                
                build_btn.click(
                    fn=self.build_kb_stream,
                    inputs=[docs_dir_input, rebuild_checkbox],
                    outputs=build_output
                )
                
                gr.Markdown("""
                ### ğŸ“‹ æ„å»ºæ­¥éª¤
                
                1. å‡†å¤‡æ–‡æ¡£æ–‡ä»¶ï¼ˆæ”¯æŒ txtã€pdfã€docxã€mdã€epub æ ¼å¼ï¼‰
                2. å°†æ–‡æ¡£æ”¾å…¥ `docs` ç›®å½•ï¼ˆæˆ–è‡ªå®šä¹‰ç›®å½•ï¼‰
                3. ç‚¹å‡»"å¼€å§‹æ„å»º"æŒ‰é’®
                4. ç­‰å¾…æ„å»ºå®Œæˆï¼ˆé¦–æ¬¡å¯èƒ½éœ€è¦ä¸‹è½½åµŒå…¥æ¨¡å‹ï¼‰
                5. åˆ‡æ¢åˆ°"å¯¹è¯æŸ¥è¯¢"æ ‡ç­¾é¡µå¼€å§‹æé—®
                
                ### âš™ï¸ é…ç½®è¯´æ˜
                
                å¯ä»¥åœ¨ `config.yaml` ä¸­ä¿®æ”¹ï¼š
                - Ollama æ¨¡å‹é€‰æ‹©
                - åµŒå…¥æ¨¡å‹é€‰æ‹©
                - æ–‡æ¡£åˆ†å—å¤§å°
                - æ£€ç´¢å‚æ•°ç­‰
                """)
            
            with gr.Tab("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯"):
                gr.Markdown("""
                ## ç³»ç»Ÿé…ç½®
                
                ### å½“å‰æ¨¡å‹
                - **LLM**: qwen3 (ä¸­æ–‡ä¼˜åŒ–)
                - **åµŒå…¥**: Sentence Transformers (å¤šè¯­è¨€)
                - **å‘é‡åº“**: ChromaDB
                
                ### ç¡¬ä»¶è¦æ±‚
                   - æœ€ä½: 8GB RAM
                   - æ¨è: 16GB RAM + GPU
                
                ### æ•…éšœæ’æŸ¥
                - **Ollama è¿æ¥å¤±è´¥**: è¿è¡Œ `ollama serve`
                - **å†…å­˜ä¸è¶³**: å‡å° chunk_size å€¼
                - **æŸ¥è¯¢ç¼“æ…¢**: å‡å°‘æ£€ç´¢æ–‡æ¡£æ•°é‡
                """)
        
        # å¯åŠ¨æœåŠ¡
            demo.launch(
                server_name="0.0.0.0",
                server_port=7873,
                share=False,
                show_error=True,
                inbrowser=True
            )


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ­£åœ¨å¯åŠ¨æœ¬åœ°çŸ¥è¯†åº“ Web UI...")
    print("ğŸ“ è¯·ç¡®ä¿å·²ç»å®‰è£… Ollama å¹¶ä¸‹è½½äº†æ¨¡å‹")
    print("ğŸ’¡ è®¿é—®åœ°å€: http://localhost:7860\n")
    
    ui = KnowledgeBaseUI()
    ui.launch()


if __name__ == "__main__":
    main()

